{
  "version": "1.0",
  "projectName": "slack-bot-llm-router",
  "description": "Replace the keyword-based Slack bot intent router with an LLM-powered classifier",
  "stories": [
    {
      "id": "story-ml8av3di",
      "title": "LLM-Powered Slack Intent Router",
      "description": "Replace the keyword-matching intent router in the Slack bot with an LLM-powered classifier that can understand natural language requests.\n\n## Problem\nThe current router (`packages/slack/src/intents/router.ts`) uses `normalized.includes('status')` style keyword matching. Anything that doesn't hit exact keywords returns \"I didn't understand that request.\" This makes the bot useless for natural language like \"get me a list of recent emails from ai hero\" or \"what conversations came in today about refunds\".\n\n## Current Architecture\n- `packages/slack/src/intents/router.ts` â€” `routeIntent(rawText)` does keyword matching â†’ returns `ParsedIntent`\n- `packages/slack/src/intents/executor.ts` â€” `executeIntent(intent, context)` handles the actual work (Front API calls, etc.)\n- `packages/slack/src/intents/types.ts` â€” `IntentCategory` union type + `ParsedIntent` interface\n- `packages/slack/src/handlers/mention.ts` â€” Entry point when bot is @mentioned\n\n## Solution\nAdd an LLM fallback to `routeIntent()`:\n1. Keep existing keyword matching as fast-path (no API call needed for obvious intents)\n2. When keyword matching returns `unknown`, call an LLM to classify the intent\n3. The LLM should extract: intent category, entities (email, name, search query, product name), and confidence\n4. Add a new intent category `general_query` for open-ended questions the bot should try to answer\n5. Expand the executor to handle `general_query` with a Front API search\n\n## Files to Modify\n- `packages/slack/src/intents/router.ts` â€” Add `routeIntentWithLLM()` async function as fallback\n- `packages/slack/src/intents/types.ts` â€” Add `general_query` to IntentCategory, add `query` to entities\n- `packages/slack/src/intents/executor.ts` â€” Add `general_query` handler that searches Front\n- `packages/slack/src/handlers/mention.ts` â€” Use async router when keyword match fails\n\n## Files to Create\n- `packages/slack/src/intents/llm-classifier.ts` â€” LLM classification function\n- `packages/slack/src/intents/__tests__/llm-classifier.test.ts` â€” Tests with mocked LLM responses\n\n## LLM Classifier Design\n```typescript\n// llm-classifier.ts\nimport { generateObject } from 'ai'\nimport { z } from 'zod'\n\nconst IntentSchema = z.object({\n  category: z.enum(['status_query', 'context_lookup', 'escalation', 'draft_action', 'general_query']),\n  confidence: z.number().min(0).max(1),\n  entities: z.object({\n    email: z.string().optional(),\n    name: z.string().optional(),\n    query: z.string().optional(),\n    product: z.string().optional(),\n  }),\n  reasoning: z.string(),\n})\n\nexport async function classifyIntent(rawText: string): Promise<ParsedIntent> {\n  const result = await generateObject({\n    model: openai('gpt-4o-mini'),  // cheap + fast\n    schema: IntentSchema,\n    prompt: `You are a support team Slack bot intent classifier.\n    \nClassify this message from a team member:\n\"${rawText}\"\n\nCategories:\n- status_query: asking about pending/urgent/open conversations\n- context_lookup: looking up a specific customer or conversation (by email, name, product)\n- escalation: wants to escalate something to a teammate\n- draft_action: feedback on a draft response (approve, rewrite, shorten)\n- general_query: any other support-related question that could be answered by searching conversations\n\nExtract any entities: email addresses, person names, search queries, product names (AI Hero, Total TypeScript, Pro Tailwind, Epic Web, etc.).`,\n  })\n  \n  return {\n    category: result.object.category,\n    confidence: result.object.confidence,\n    entities: Object.fromEntries(\n      Object.entries(result.object.entities).filter(([_, v]) => v !== undefined)\n    ),\n    rawText,\n  }\n}\n```\n\n## Router Update\n```typescript\n// In router.ts - make routeIntent async with LLM fallback\nexport async function routeIntent(rawText: string): Promise<{ intent: ParsedIntent; response: string }> {\n  // Fast path: keyword matching (existing logic)\n  const keywordResult = routeIntentByKeyword(rawText)\n  if (keywordResult.intent.category !== 'unknown') {\n    return keywordResult\n  }\n  \n  // Slow path: LLM classification\n  try {\n    const classified = await classifyIntent(rawText)\n    if (classified.confidence > 0.5) {\n      return {\n        intent: classified,\n        response: getResponseForIntent(classified),\n      }\n    }\n  } catch (error) {\n    console.error('LLM classification failed, falling back to unknown:', error)\n  }\n  \n  // Final fallback\n  return keywordResult\n}\n```\n\n## General Query Executor\nFor `general_query` intents, search Front conversations using the extracted query/product:\n```typescript\ncase 'general_query': {\n  const query = intent.entities.query || intent.entities.product || intent.rawText\n  await updateStatus(context, `ðŸ” Searching for \"${query}\"...`)\n  const conversations = await front.conversations.search(query)\n  // Format and return results similar to context_lookup\n}\n```\n\n## Key Requirements\n- Use `ai` SDK (already in monorepo) with `openai` provider\n- Use `gpt-4o-mini` for speed and cost (this is a Slack bot, latency matters)\n- Use `generateObject` with Zod schema for structured output\n- Keep keyword matching as fast path (zero latency for obvious intents)\n- LLM fallback only triggers on `unknown` intent\n- Handle LLM failures gracefully (fall back to keyword result)\n- Add Skill Recordings product names to the classifier prompt for entity extraction\n- Tests should mock the `ai` SDK's `generateObject` function\n\n## Environment\n- OPENAI_API_KEY should already be available (check process.env)\n- If not, use the existing secrets infrastructure\n\n## TDD\nWrite tests first for the LLM classifier with mocked responses covering:\n- \"get me recent emails from ai hero\" â†’ general_query with product: \"AI Hero\"\n- \"anything urgent?\" â†’ status_query (keyword fast path, no LLM needed)\n- \"lookup john@example.com\" â†’ context_lookup with email (keyword fast path)\n- \"what refund requests came in today\" â†’ general_query with query\n- Empty/gibberish input â†’ low confidence, falls back to help message\n\n## On Completion\nCreate a git branch, commit, and push. Commit: `feat(slack): LLM-powered intent router with keyword fast path`",
      "priority": 1,
      "passes": true,
      "validationCommand": "cd packages/slack && bun run check-types 2>/dev/null; cd ../.. && bun run test --filter slack 2>/dev/null || (cd packages/slack && bunx vitest --run 2>/dev/null) || echo \"tests passed or no test runner configured\"",
      "acceptanceCriteria": [
        "LLM classifier uses generateObject with Zod schema",
        "Keyword matching still works as fast path (no API call)",
        "Unknown intents fall back to LLM classification",
        "general_query intent category added and handled",
        "Front search executed for general queries",
        "Product names extracted (AI Hero, Total TypeScript, etc.)",
        "LLM failures fall back gracefully to help message",
        "Tests cover keyword fast path and LLM fallback",
        "All types pass check-types"
      ]
    }
  ],
  "metadata": {
    "createdAt": "2026-02-04T17:26:13.407Z",
    "totalIterations": 1,
    "lastIteration": "2026-02-04T17:30:24.520Z"
  }
}