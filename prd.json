{
  "version": "1.0",
  "projectName": "cli-rearchitect-review-fixes",
  "description": "Code review fixes for the CLI rearchitect branch. Addresses DRY violations, ghost completions, coverage gaps, and cleanup.",
  "stories": [
    {
      "id": "story-ml8kfqe1",
      "title": "Extract shared Front client helpers to front/client.ts",
      "description": "## Problem\n`requireFrontToken()`, `getFrontClient()`, and `normalizeId()` are copy-pasted identically across 11 files in `packages/cli/src/commands/front/`. This is a DRY violation that will rot — someone fixes the error message in one place, not the other 10.\n\n## Duplicated in these files\n- api.ts, archive.ts, assign.ts, bulk-assign.ts, bulk-archive.ts (if exists)\n- conversation-tags.ts, inbox.ts, index.ts, reply.ts, report.ts, tags.ts, triage.ts\n\n## Task\n\n### 1. Create `packages/cli/src/commands/front/client.ts`\nExtract and export these shared helpers:\n\n```typescript\nimport { createInstrumentedFrontClient } from '@skillrecordings/core/front/instrumented-client'\nimport { CLIError } from '../../core/errors'\n\nexport function requireFrontToken(): string {\n  const apiToken = process.env.FRONT_API_TOKEN\n  if (!apiToken) {\n    throw new CLIError({\n      userMessage: 'FRONT_API_TOKEN environment variable is required.',\n      suggestion: 'Set FRONT_API_TOKEN in your shell or .env.local, or run: skill auth setup',\n    })\n  }\n  return apiToken\n}\n\nexport function getFrontClient() {\n  return createInstrumentedFrontClient({ apiToken: requireFrontToken() })\n}\n\nexport function normalizeId(idOrUrl: string): string {\n  return idOrUrl.startsWith('http') ? idOrUrl.split('/').pop()! : idOrUrl\n}\n```\n\n### 2. Update all 11 Front command files\nReplace the local `requireFrontToken`, `getFrontClient`, and `normalizeId` functions with imports from `./client`. Delete the local copies entirely.\n\nFiles to update:\n- `packages/cli/src/commands/front/api.ts`\n- `packages/cli/src/commands/front/archive.ts`\n- `packages/cli/src/commands/front/assign.ts`\n- `packages/cli/src/commands/front/bulk-assign.ts`\n- `packages/cli/src/commands/front/conversation-tags.ts`\n- `packages/cli/src/commands/front/inbox.ts`\n- `packages/cli/src/commands/front/index.ts`\n- `packages/cli/src/commands/front/reply.ts`\n- `packages/cli/src/commands/front/report.ts`\n- `packages/cli/src/commands/front/tags.ts`\n- `packages/cli/src/commands/front/triage.ts`\n\nAlso check `packages/cli/src/commands/front/bulk-archive.ts` and `packages/cli/src/commands/front/pull-conversations.ts` — if they have copies too, extract those.\n\n### 3. Add unit test for client.ts\nCreate `packages/cli/tests/unit/commands/front/client.test.ts`:\n- Test `requireFrontToken()` throws CLIError when FRONT_API_TOKEN not set\n- Test `requireFrontToken()` returns token when set\n- Test `normalizeId()` strips URL prefix\n- Test `normalizeId()` passes through plain IDs\n- Test `getFrontClient()` calls createInstrumentedFrontClient with token\n\n### 4. Verify no local copies remain\nAfter changes, run: `grep -rn \"function requireFrontToken\" packages/cli/src/commands/front/`\nShould show ONLY `client.ts`. If any other file still has it, you missed one.\n\n## Important\n- Do NOT change any behavior — this is a pure refactor\n- All existing tests must continue to pass unchanged\n- The mock in `tests/integration/commands/front.test.ts` mocks `@skillrecordings/core/front/instrumented-client` which is still the underlying import — it should still work\n\n## Progress Notification\nOn completion, append to `packages/cli/PROGRESS.md`:\n```\n## Review Fix 1: Extract shared Front client helpers\n- Created `src/commands/front/client.ts` with requireFrontToken, getFrontClient, normalizeId\n- Updated 11+ files to import from shared module\n- Added unit tests for client.ts\n- Verified no duplicate copies remain\n```",
      "priority": 1,
      "passes": true,
      "validationCommand": "cd packages/cli && bun run check-types && bun run test",
      "acceptanceCriteria": [
        "packages/cli/src/commands/front/client.ts exists with requireFrontToken, getFrontClient, normalizeId exports",
        "All 11+ front command files import from ./client instead of defining locally",
        "grep -rn 'function requireFrontToken' shows ONLY client.ts",
        "Unit tests for client.ts pass",
        "All existing tests pass unchanged",
        "No behavior changes — pure refactor"
      ]
    },
    {
      "id": "story-ml8kghxx",
      "title": "Implement MCP Server Mode (Phase 4 redo)",
      "description": "## Problem\nStory 12 (MCP Server Mode, Issue #188) was ghost-completed — the commit only touched prd.json and progress.txt. NO MCP server implementation exists. This story implements it properly.\n\n## What MCP Server Mode Is\nModel Context Protocol (MCP) lets AI coding agents (Claude Code, Cursor, etc.) call the CLI as a tool server over stdio. Instead of shelling out to `skill front inbox ...`, the agent connects to `skill mcp` and calls structured tools with JSON-RPC.\n\n## Task\n\n### 1. Create `packages/cli/src/mcp/server.ts`\nImplement a minimal MCP server using stdio transport (stdin/stdout JSON-RPC):\n\n```typescript\n// MCP JSON-RPC protocol over stdio\n// Spec: https://modelcontextprotocol.io/specification\n\nexport interface McpTool {\n  name: string\n  description: string\n  inputSchema: Record<string, unknown>  // JSON Schema\n}\n\nexport interface McpServer {\n  start(): Promise<void>\n  stop(): void\n}\n```\n\nThe server should:\n- Listen on stdin for JSON-RPC messages\n- Respond on stdout\n- Handle `initialize`, `tools/list`, `tools/call` methods\n- Support `notifications/initialized` from client\n- Exit cleanly on stdin close or SIGTERM\n\n### 2. Create `packages/cli/src/mcp/tools.ts`\nRegister CLI commands as MCP tools. Start with a core set:\n\n```typescript\nconst tools: McpTool[] = [\n  {\n    name: 'front_inbox_list',\n    description: 'List Front inboxes',\n    inputSchema: { type: 'object', properties: { json: { type: 'boolean' } } }\n  },\n  {\n    name: 'front_inbox_conversations',\n    description: 'List conversations in a Front inbox',\n    inputSchema: {\n      type: 'object',\n      properties: {\n        inbox: { type: 'string', description: 'Inbox name or ID' },\n        status: { type: 'string', enum: ['unassigned', 'assigned', 'archived'] },\n        limit: { type: 'number', default: 25 }\n      },\n      required: ['inbox']\n    }\n  },\n  {\n    name: 'front_conversation_get',\n    description: 'Get conversation details with messages',\n    inputSchema: {\n      type: 'object',\n      properties: {\n        id: { type: 'string', description: 'Conversation ID (cnv_xxx)' },\n        messages: { type: 'boolean', default: false }\n      },\n      required: ['id']\n    }\n  },\n  {\n    name: 'front_assign',\n    description: 'Assign or unassign a conversation',\n    inputSchema: {\n      type: 'object',\n      properties: {\n        id: { type: 'string' },\n        to: { type: 'string', description: 'Teammate ID (tea_xxx)' },\n        unassign: { type: 'boolean' }\n      },\n      required: ['id']\n    }\n  },\n  {\n    name: 'front_reply',\n    description: 'Draft a reply on a conversation (creates draft, never sends)',\n    inputSchema: {\n      type: 'object',\n      properties: {\n        id: { type: 'string' },\n        message: { type: 'string' }\n      },\n      required: ['id', 'message']\n    }\n  },\n  {\n    name: 'front_archive',\n    description: 'Archive a conversation',\n    inputSchema: {\n      type: 'object',\n      properties: { id: { type: 'string' } },\n      required: ['id']\n    }\n  },\n  {\n    name: 'front_tag',\n    description: 'Add or remove a tag on a conversation',\n    inputSchema: {\n      type: 'object',\n      properties: {\n        id: { type: 'string' },\n        tag: { type: 'string' },\n        remove: { type: 'boolean', default: false }\n      },\n      required: ['id', 'tag']\n    }\n  },\n  {\n    name: 'front_search',\n    description: 'Search Front conversations',\n    inputSchema: {\n      type: 'object',\n      properties: {\n        query: { type: 'string' },\n        limit: { type: 'number', default: 25 }\n      },\n      required: ['query']\n    }\n  },\n  {\n    name: 'front_api',\n    description: 'Raw Front API passthrough (GET only unless --allow-destructive)',\n    inputSchema: {\n      type: 'object',\n      properties: {\n        method: { type: 'string', enum: ['GET', 'POST', 'PATCH', 'DELETE'] },\n        path: { type: 'string' },\n        data: { type: 'string', description: 'JSON body for POST/PATCH' },\n        allowDestructive: { type: 'boolean', default: false }\n      },\n      required: ['method', 'path']\n    }\n  }\n]\n```\n\n### 3. Tool execution bridge\nEach tool call should:\n1. Create a CommandContext with JSON output format\n2. Capture stdout/stderr via PassThrough streams (same pattern as test-context.ts)\n3. Call the existing exported action function (e.g., `listInboxes(ctx, options)`)\n4. Return the captured JSON as the tool result\n5. Return errors as `isError: true` content\n\nThis reuses ALL existing command logic — no duplication.\n\n### 4. Register `skill mcp` command\nIn `packages/cli/src/index.ts`, add:\n```typescript\nprogram\n  .command('mcp')\n  .description('Start MCP server for AI coding agent integration')\n  .action(async () => {\n    const server = createMcpServer()\n    await server.start()\n  })\n```\n\n### 5. Tests\nCreate `packages/cli/tests/unit/mcp/server.test.ts`:\n- Test tools/list returns all registered tools\n- Test tools/call for front_inbox_list returns valid response\n- Test tools/call with unknown tool returns error\n- Test initialize handshake\n- Mock the Front client (same pattern as front.test.ts)\n\nCreate `packages/cli/tests/unit/mcp/tools.test.ts`:\n- Test tool registry has correct schemas\n- Test each tool's inputSchema is valid JSON Schema\n\n### 6. Do NOT use any external MCP library\nImplement the JSON-RPC protocol directly — it's simple:\n- Read newline-delimited JSON from stdin\n- Parse `{ jsonrpc: \"2.0\", method: string, params: object, id: number }`\n- Respond with `{ jsonrpc: \"2.0\", result: object, id: number }`\n- Errors: `{ jsonrpc: \"2.0\", error: { code: number, message: string }, id: number }`\n\n## Important\n- MCP communication uses stdout — all human/debug output MUST go to stderr\n- The server must handle stdin close gracefully (client disconnected)\n- Tool results should include HATEOAS `_actions` so agents know what to do next\n\n## Progress Notification\nOn completion, append to `packages/cli/PROGRESS.md`:\n```\n## Review Fix 2: MCP Server Mode (Phase 4 redo)\n- Created MCP JSON-RPC server over stdio (no external deps)\n- Registered 9 Front tools with JSON Schema input validation\n- Tool execution bridges to existing command functions via captured context\n- Added `skill mcp` command\n- Tests for server handshake, tool listing, tool execution, error handling\n```",
      "priority": 2,
      "passes": true,
      "validationCommand": "cd packages/cli && bun run check-types && bun run test",
      "acceptanceCriteria": [
        "packages/cli/src/mcp/server.ts implements JSON-RPC over stdio",
        "packages/cli/src/mcp/tools.ts registers 9+ Front tools with JSON Schema",
        "skill mcp command registered in src/index.ts",
        "Tool calls bridge to existing action functions via captured CommandContext",
        "tools/list returns all tools with descriptions and schemas",
        "tools/call executes tool and returns result",
        "Unknown tool returns proper JSON-RPC error",
        "Server handles stdin close gracefully",
        "All tests pass including new MCP tests",
        "No external MCP library used — pure JSON-RPC implementation"
      ]
    },
    {
      "id": "story-ml8kgz82",
      "title": "CSV injection sanitization in list-output.ts",
      "description": "## Problem\n`packages/cli/src/core/list-output.ts` has a `toCsvCell()` function that handles quoting for commas and newlines, but does NOT sanitize formula-injection characters. If a Front conversation subject starts with `=`, `+`, `-`, or `@`, the CSV output could trigger formula execution when opened in Excel/Google Sheets.\n\nThis is a support CLI that outputs user-controlled data (email subjects, conversation bodies). CSV injection is a real (if niche) risk.\n\n## Task\n\n### 1. Update `toCsvCell()` in `packages/cli/src/core/list-output.ts`\n\nAdd formula injection sanitization. If a cell value starts with `=`, `+`, `-`, `@`, `\\t`, or `\\r`, prefix it with a single quote (`'`) which Excel treats as a text indicator:\n\n```typescript\nconst FORMULA_PREFIXES = ['=', '+', '-', '@', '\\t', '\\r']\n\nconst toCsvCell = (value: unknown): string => {\n  if (value === null || value === undefined) return ''\n  const raw =\n    typeof value === 'string'\n      ? value\n      : typeof value === 'number' || typeof value === 'boolean'\n        ? String(value)\n        : JSON.stringify(value)\n\n  // Sanitize formula injection\n  const sanitized = FORMULA_PREFIXES.some(p => raw.startsWith(p))\n    ? `'${raw}`\n    : raw\n\n  if (/[\",\\n]/.test(sanitized)) {\n    return `\"${sanitized.replace(/\"/g, '\"\"')}\"`\n  }\n  return sanitized\n}\n```\n\n**Important edge case:** Negative numbers like `-5` should NOT be sanitized (they're valid numbers, not formulas). Only sanitize if the value is a string type — numbers and booleans are safe. Adjust the logic:\n\n```typescript\nconst toCsvCell = (value: unknown): string => {\n  if (value === null || value === undefined) return ''\n\n  // Numbers and booleans are safe — no formula risk\n  if (typeof value === 'number' || typeof value === 'boolean') {\n    return String(value)\n  }\n\n  const raw = typeof value === 'string' ? value : JSON.stringify(value)\n\n  // Sanitize string values that could be interpreted as formulas\n  const sanitized = FORMULA_PREFIXES.some(p => raw.startsWith(p))\n    ? `'${raw}`\n    : raw\n\n  if (/[\",\\n]/.test(sanitized)) {\n    return `\"${sanitized.replace(/\"/g, '\"\"')}\"`\n  }\n  return sanitized\n}\n```\n\n### 2. Add tests in `packages/cli/tests/unit/core/list-output.test.ts`\n\nCreate a new test file:\n\n```typescript\nimport { describe, it, expect } from 'vitest'\n// You'll need to either export toCsvCell or test via outputList\n\ndescribe('CSV output sanitization', () => {\n  it('sanitizes formula injection in strings starting with =', ...)\n  it('sanitizes formula injection in strings starting with +', ...)\n  it('sanitizes formula injection in strings starting with -', ...)\n  it('sanitizes formula injection in strings starting with @', ...)\n  it('does NOT sanitize negative numbers', ...)\n  it('does NOT sanitize boolean values', ...)\n  it('handles normal strings unchanged', ...)\n  it('still quotes strings with commas', ...)\n  it('still quotes strings with newlines', ...)\n  it('handles null and undefined as empty string', ...)\n})\n```\n\nIf `toCsvCell` is not exported, test through `outputList()` with CSV format by providing items with formula-like values and checking the output.\n\n### 3. Consider exporting toCsvCell for testability\nIf it's currently a module-private const, either:\n- Export it directly (preferred for a utility function)\n- Or test through the public `outputList` API\n\n## Progress Notification\nOn completion, append to `packages/cli/PROGRESS.md`:\n```\n## Review Fix 3: CSV injection sanitization\n- Added formula-injection prefix sanitization to toCsvCell()\n- Handles =, +, -, @, tab, CR prefixes on string values\n- Numbers and booleans bypass sanitization (no formula risk)\n- Added comprehensive unit tests for CSV output\n```",
      "priority": 3,
      "passes": true,
      "validationCommand": "cd packages/cli && bun run check-types && bun run test",
      "acceptanceCriteria": [
        "toCsvCell sanitizes strings starting with = + - @ tab CR",
        "Negative numbers are NOT sanitized",
        "Booleans are NOT sanitized",
        "Normal strings pass through unchanged",
        "Comma and newline quoting still works correctly",
        "New test file exists with 8+ test cases",
        "All tests pass"
      ]
    },
    {
      "id": "story-ml8khlw9",
      "title": "Clean up progress.txt and add coverage verification",
      "description": "## Problem 1: progress.txt is 1,472 lines of noise\nThe progress file accumulated every failed Ralph iteration attempt. The \"Compiled Binary Build\" story alone has ~50 failed entries. This makes the repo dirty and wastes context for future agents reading it.\n\n## Problem 2: Coverage thresholds unverified\nThe vitest.config.ts sets ambitious coverage thresholds (80% general, 90% for src/core/) but we haven't verified they actually pass. The CI workflow runs `--coverage` but locally `bun run test` does not. We need to verify and adjust if needed.\n\n## Task\n\n### 1. Reset progress.txt\nReplace the entire 1,472-line progress.txt with a clean summary of what was accomplished:\n\n```\n# CLI Rearchitect — Progress\n\n## Completed Stories (Original Loop)\n1. Core Infrastructure Types (Phase 0) — context, errors, signals\n2. db-status Migration PoC (Phase 0) — test helpers, pattern demo\n3. SecretsProvider Abstraction (Phase 1) — 1Password SDK + env fallback\n4. Secret Loading Migration (Phase 1) — removed old crypto, wired providers\n5. OutputFormatter Abstraction (Phase 2) — JSON/text/table modes\n6. Command Migration Batch 1 (Phase 2) — Front + Inngest commands\n7. Command Migration Batch 2 (Phase 2) — Axiom + Tools + Memory\n8. Command Migration Batch 3 (Phase 2) — All remaining commands\n9. Dead Code Removal + Deduplication (Phase 5) — integration-client, eval-seed\n10. Compiled Binary Build Script (Phase 3) — build.ts, 4 platform targets\n11. Release Infrastructure (Phase 3) — GH Actions workflow, install.sh\n12. Test Coverage Gap Fill + CI (Phase 6) — vitest config, CI workflow\n13. Interactive Auth Setup Wizard — 1Password deep links, op CLI\n14. Claude Code Plugin — SKILL.md, plugin.json, plugin-sync command\n15. P0 Bugs — Inbox filtering + pagination fixes\n16. P1 Commands — assign, tag, reply, bulk-assign, conversation-tags\n17. P2 Improvements — pull bodies, triage LLM, report IDs\n18. P3 SDK Access — API passthrough, list-output, composability\n\n## Review Fixes (Current Loop)\n(Updated by current stories)\n```\n\n### 2. Verify coverage thresholds\nRun `bun run test --coverage` in `packages/cli/` and check if the thresholds in `vitest.config.ts` pass.\n\nIf they DON'T pass:\n- Check which files/functions are below threshold\n- If close (within 5%), add targeted tests to bring them up\n- If way below, adjust thresholds to realistic values that still provide a floor\n\nCurrent thresholds:\n```typescript\nthresholds: {\n  lines: 80,\n  functions: 80,\n  branches: 80,\n  statements: 80,\n  'src/core/': {\n    lines: 90,\n    functions: 90,\n    branches: 90,\n    statements: 90,\n  },\n}\n```\n\n### 3. Add coverage script to package.json\nEnsure `packages/cli/package.json` has:\n```json\n{\n  \"scripts\": {\n    \"test:coverage\": \"vitest run --coverage\"\n  }\n}\n```\n\n### 4. Update vitest config if needed\nIf coverage thresholds need adjustment, set them to the actual current level minus 2% (as a regression floor, not an aspirational target). Document why in a comment.\n\n## Important\n- Do NOT delete progress.txt — replace its contents\n- The coverage check may fail initially — that's expected, fix or adjust\n- If adding tests to meet coverage, focus on src/core/ files first (they have the 90% threshold)\n\n## Progress Notification\nOn completion, append to `packages/cli/PROGRESS.md`:\n```\n## Review Fix 4: Cleanup + coverage verification\n- Reset progress.txt from 1,472 lines to clean summary\n- Verified coverage thresholds: [actual percentages]\n- [Adjusted thresholds to X%] OR [Added tests to meet thresholds]\n- Added test:coverage script to package.json\n```",
      "priority": 4,
      "passes": true,
      "validationCommand": "cd packages/cli && bun run check-types && bun run test",
      "acceptanceCriteria": [
        "progress.txt is under 50 lines with clean summary",
        "test:coverage script exists in package.json",
        "Coverage thresholds are realistic and pass (or are documented as aspirational)",
        "All existing tests still pass",
        "packages/cli/PROGRESS.md updated"
      ]
    },
    {
      "id": "story-ml8ki0tm",
      "title": "Deduplicate command registration pattern + createContext boilerplate",
      "description": "## Problem\nEvery `registerXxxCommand()` function has the same boilerplate for extracting global options and creating a context:\n\n```typescript\n.action(async (arg: string, options: XxxOptions, command: Command) => {\n  const opts = typeof command.optsWithGlobals === 'function'\n    ? command.optsWithGlobals()\n    : { ...command.parent?.opts(), ...command.opts() }\n  const ctx = await createContext({\n    format: options.json ? 'json' : opts.format,\n    verbose: opts.verbose,\n    quiet: opts.quiet,\n  })\n  await someAction(ctx, arg, options)\n})\n```\n\nThis 8-line pattern is repeated in assign.ts, reply.ts, conversation-tags.ts, bulk-assign.ts, api.ts, and others. It should be a shared helper.\n\n## Task\n\n### 1. Create `packages/cli/src/commands/front/with-context.ts`\n\n```typescript\nimport type { Command } from 'commander'\nimport { type CommandContext, createContext } from '../../core/context'\n\ntype JsonOption = { json?: boolean }\n\n/**\n * Extract global CLI options from a Commander command and create a CommandContext.\n * Use this in .action() handlers to avoid repeating the same boilerplate.\n */\nexport async function contextFromCommand(\n  command: Command,\n  options: JsonOption = {}\n): Promise<CommandContext> {\n  const opts = typeof command.optsWithGlobals === 'function'\n    ? command.optsWithGlobals()\n    : { ...command.parent?.opts(), ...command.opts() }\n\n  return createContext({\n    format: options.json ? 'json' : opts.format,\n    verbose: opts.verbose,\n    quiet: opts.quiet,\n  })\n}\n```\n\n### 2. Update command registration functions\nReplace the inline boilerplate in these files with `contextFromCommand()`:\n- `packages/cli/src/commands/front/assign.ts`\n- `packages/cli/src/commands/front/reply.ts`\n- `packages/cli/src/commands/front/conversation-tags.ts` (both tag and untag commands)\n- `packages/cli/src/commands/front/bulk-assign.ts`\n- `packages/cli/src/commands/front/api.ts`\n\nBefore:\n```typescript\n.action(async (conversationId: string, options: AssignOptions, command: Command) => {\n  const opts = typeof command.optsWithGlobals === 'function'\n    ? command.optsWithGlobals()\n    : { ...command.parent?.opts(), ...command.opts() }\n  const ctx = await createContext({\n    format: options.json ? 'json' : opts.format,\n    verbose: opts.verbose,\n    quiet: opts.quiet,\n  })\n  await assignConversation(ctx, conversationId, options)\n})\n```\n\nAfter:\n```typescript\n.action(async (conversationId: string, options: AssignOptions, command: Command) => {\n  const ctx = await contextFromCommand(command, options)\n  await assignConversation(ctx, conversationId, options)\n})\n```\n\n### 3. Add test for contextFromCommand\nIn `packages/cli/tests/unit/commands/front/with-context.test.ts`:\n- Test with mock Command object that has optsWithGlobals\n- Test fallback when optsWithGlobals doesn't exist\n- Test json option override\n- Test verbose/quiet propagation\n\n### 4. Verify no behavior change\nAll existing tests must pass unchanged. This is a pure refactor.\n\n## Important\n- Only update files that have the EXACT boilerplate pattern. Don't change files that have custom context creation logic.\n- The action functions (assignConversation, replyToConversation, etc.) are NOT changed — only the .action() wrappers.\n\n## Progress Notification\nOn completion, append to `packages/cli/PROGRESS.md`:\n```\n## Review Fix 5: Deduplicate command registration boilerplate\n- Created contextFromCommand() helper in front/with-context.ts\n- Updated 5+ command registration functions to use shared helper\n- Added unit tests for contextFromCommand\n- Pure refactor — no behavior changes\n```",
      "priority": 5,
      "passes": true,
      "validationCommand": "cd packages/cli && bun run check-types && bun run test",
      "acceptanceCriteria": [
        "packages/cli/src/commands/front/with-context.ts exports contextFromCommand",
        "5+ command files updated to use contextFromCommand",
        "Unit test for contextFromCommand passes",
        "All existing tests pass unchanged",
        "No behavior changes — pure refactor"
      ]
    },
    {
      "id": "story-ml8n50tz",
      "title": "Intelligent Front API response caching with TTL tiers and mutation invalidation",
      "description": "## Problem\nEvery `getFrontClient()` call creates a fresh client with zero caching. In MCP server mode and agent-driven triage sessions, this means redundant API calls:\n- Tags list is re-fetched on every tag/untag operation (paginated — multiple API calls just to resolve one tag name)\n- Inbox list is re-fetched on every inbox name lookup\n- Conversation details fetched multiple times in a triage loop\n- Cross-conversation lookups hit the same customer's conversations repeatedly\n\n## Architecture: HTTP-Level Cache with TTL Tiers\n\nCache at the HTTP GET response level (by URL), not the domain level. This means zero changes to command code.\n\n### 1. Create `packages/cli/src/commands/front/cache.ts`\n\n```typescript\nexport interface CacheEntry<T = unknown> {\n  data: T\n  timestamp: number\n  url: string\n}\n\nexport type CacheTier = 'static' | 'warm' | 'hot'\n\nexport interface FrontCacheConfig {\n  /** Static tier TTL in ms — inboxes, teammates. Default: Infinity (never expires within session) */\n  staticTtlMs: number\n  /** Warm tier TTL in ms — tags. Default: 300_000 (5 min) */\n  warmTtlMs: number\n  /** Hot tier TTL in ms — conversations, messages. Default: 30_000 (30s) */\n  hotTtlMs: number\n  /** Whether caching is enabled at all. Default: true */\n  enabled: boolean\n}\n\nexport const DEFAULT_CACHE_CONFIG: FrontCacheConfig = {\n  staticTtlMs: Number.POSITIVE_INFINITY,\n  warmTtlMs: 300_000,\n  hotTtlMs: 30_000,\n  enabled: true,\n}\n```\n\n**URL-to-tier mapping rules:**\n- `/inboxes` (list), `/teammates` → `static`\n- `/tags` → `warm`\n- `/conversations`, `/messages`, everything else → `hot`\n\n```typescript\nexport function classifyUrl(url: string): CacheTier {\n  const path = url.startsWith('http') ? new URL(url).pathname : url\n  // Static: inbox list, teammate list (not conversations within an inbox)\n  if (/^\\/inboxes\\/?$/.test(path) || /^\\/teammates/.test(path)) return 'static'\n  // Warm: tags\n  if (/^\\/tags/.test(path)) return 'warm'\n  // Hot: everything else\n  return 'hot'\n}\n```\n\n**Core cache class:**\n\n```typescript\nexport class FrontResponseCache {\n  private entries = new Map<string, CacheEntry>()\n  private config: FrontCacheConfig\n\n  constructor(config: Partial<FrontCacheConfig> = {}) {\n    this.config = { ...DEFAULT_CACHE_CONFIG, ...config }\n  }\n\n  /** Get cached response for a URL, or undefined if miss/expired */\n  get<T>(url: string): T | undefined {\n    if (!this.config.enabled) return undefined\n    const entry = this.entries.get(url)\n    if (!entry) return undefined\n    const tier = classifyUrl(url)\n    const ttl = this.ttlForTier(tier)\n    if (Date.now() - entry.timestamp > ttl) {\n      this.entries.delete(url)\n      return undefined\n    }\n    return entry.data as T\n  }\n\n  /** Store a GET response */\n  set(url: string, data: unknown): void {\n    if (!this.config.enabled) return\n    this.entries.set(url, { data, timestamp: Date.now(), url })\n  }\n\n  /** Invalidate entries matching a URL prefix pattern.\n   *  Called after mutations (POST/PATCH/DELETE). */\n  invalidate(urlPattern: string): void {\n    for (const [key] of this.entries) {\n      if (key.includes(urlPattern)) {\n        this.entries.delete(key)\n      }\n    }\n  }\n\n  /** Invalidate entries by tier */\n  invalidateTier(tier: CacheTier): void {\n    for (const [key] of this.entries) {\n      if (classifyUrl(key) === tier) {\n        this.entries.delete(key)\n      }\n    }\n  }\n\n  /** Clear everything */\n  clear(): void {\n    this.entries.clear()\n  }\n\n  /** Stats for debugging */\n  stats(): { size: number; tiers: Record<CacheTier, number> } {\n    const tiers: Record<CacheTier, number> = { static: 0, warm: 0, hot: 0 }\n    for (const [key] of this.entries) {\n      tiers[classifyUrl(key)]++\n    }\n    return { size: this.entries.size, tiers }\n  }\n\n  private ttlForTier(tier: CacheTier): number {\n    switch (tier) {\n      case 'static': return this.config.staticTtlMs\n      case 'warm': return this.config.warmTtlMs\n      case 'hot': return this.config.hotTtlMs\n    }\n  }\n}\n```\n\n### 2. Create cached client wrapper in `packages/cli/src/commands/front/client.ts`\n\nAdd a `createCachedFrontClient()` that wraps the raw client's HTTP methods:\n\n```typescript\nimport { FrontResponseCache, DEFAULT_CACHE_CONFIG, type FrontCacheConfig } from './cache'\n\n// Module-level cache — shared across all getFrontClient() calls within a process\n// Dies with the process for CLI mode, persists across tool calls in MCP mode\nlet sharedCache: FrontResponseCache | null = null\n\nfunction getSharedCache(): FrontResponseCache {\n  if (!sharedCache) {\n    sharedCache = new FrontResponseCache()\n  }\n  return sharedCache\n}\n\n/** Reset cache (for testing or explicit invalidation) */\nexport function resetFrontCache(): void {\n  sharedCache = null\n}\n\n/** Get cache stats (for debugging / health command) */\nexport function getFrontCacheStats() {\n  return sharedCache?.stats() ?? { size: 0, tiers: { static: 0, warm: 0, hot: 0 } }\n}\n\nexport function getFrontClient() {\n  const inner = createInstrumentedFrontClient({ apiToken: requireFrontToken() })\n  const cache = getSharedCache()\n\n  // Wrap the raw client methods with caching\n  const cachedRaw = {\n    get: async <T>(path: string, schema?: unknown): Promise<T> => {\n      const cached = cache.get<T>(path)\n      if (cached !== undefined) return cached\n      const result = await inner.raw.get<T>(path, schema as any)\n      cache.set(path, result)\n      return result\n    },\n    post: async <T>(path: string, body: unknown, schema?: unknown): Promise<T> => {\n      const result = await inner.raw.post<T>(path, body, schema as any)\n      // Invalidate related cache entries after mutation\n      cache.invalidate(extractResourcePath(path))\n      return result\n    },\n    patch: async <T>(path: string, body: unknown, schema?: unknown): Promise<T> => {\n      const result = await inner.raw.patch<T>(path, body, schema as any)\n      cache.invalidate(extractResourcePath(path))\n      return result\n    },\n    delete: async <T>(path: string, schema?: unknown): Promise<T> => {\n      const result = await inner.raw.delete<T>(path, schema as any)\n      cache.invalidate(extractResourcePath(path))\n      return result\n    },\n  }\n\n  // Return the client with cached raw, and sub-clients that use the same underlying fetch\n  // The sub-clients (conversations, tags, etc.) use raw internally, so they get caching for free\n  return {\n    ...inner,\n    raw: cachedRaw,\n  }\n}\n```\n\nThe `extractResourcePath()` helper extracts the base resource from a mutation URL for invalidation:\n```typescript\nfunction extractResourcePath(url: string): string {\n  // /conversations/cnv_xxx/tags → invalidate anything with /conversations/cnv_xxx\n  // /tags → invalidate /tags\n  const path = url.startsWith('http') ? new URL(url).pathname : url\n  const segments = path.split('/').filter(Boolean)\n  // Keep first two segments (resource type + ID) for targeted invalidation\n  if (segments.length >= 2) return `/${segments[0]}/${segments[1]}`\n  return `/${segments[0] ?? ''}`\n}\n```\n\n### 3. IMPORTANT: Sub-client cache transparency\n\nThe Front SDK sub-clients (conversations, tags, inboxes, etc.) are created by passing the base client's raw methods. Check how `createConversationsClient(baseClient)` works:\n\nIf sub-clients call `baseClient.get()` internally, and we replace `raw` on the outer object, the sub-clients still hold references to the ORIGINAL uncached `baseClient`. This means caching only works for `front.raw.get()` calls, NOT `front.conversations.get()`.\n\n**Fix:** We need to wrap at a lower level. Instead of replacing `raw` after construction, create the instrumented base client, then wrap ITS methods, then pass the wrapped version to the sub-client constructors.\n\nLook at how `createInstrumentedFrontClient` works and determine the right interception point. The goal is: ALL reads go through cache, regardless of whether the caller uses `front.raw.get()` or `front.conversations.get()`.\n\nIf the sub-clients are constructed with `createConversationsClient(baseClient)` where baseClient has `.get()/.post()`, then we need to wrap the baseClient BEFORE passing to sub-client constructors.\n\nCreate a new function in `client.ts`:\n\n```typescript\nexport function createCachedInstrumentedFrontClient(config: { apiToken: string }) {\n  // We need to intercept at the base client level\n  // Import the base client creator and sub-client creators\n  const cache = getSharedCache()\n  \n  // Create the base client, then wrap it\n  const baseClient = createInstrumentedBaseClient(config)\n  \n  const cachedBase = {\n    get: async <T>(path: string, schema?: any): Promise<T> => {\n      const cached = cache.get<T>(path)\n      if (cached !== undefined) return cached\n      const result = await baseClient.get<T>(path, schema)\n      cache.set(path, result)\n      return result\n    },\n    post: async <T>(path: string, body: unknown, schema?: any): Promise<T> => {\n      const result = await baseClient.post<T>(path, body, schema)\n      cache.invalidate(extractResourcePath(path))\n      return result\n    },\n    patch: async <T>(path: string, body: unknown, schema?: any): Promise<T> => {\n      const result = await baseClient.patch<T>(path, body, schema)\n      cache.invalidate(extractResourcePath(path))\n      return result\n    },\n    put: async <T>(path: string, body: unknown, schema?: any): Promise<T> => {\n      const result = await baseClient.put<T>(path, body, schema)\n      cache.invalidate(extractResourcePath(path))\n      return result\n    },\n    delete: async <T>(path: string, schema?: any): Promise<T> => {\n      const result = await baseClient.delete<T>(path, schema)\n      cache.invalidate(extractResourcePath(path))\n      return result\n    },\n  }\n  \n  // Now construct sub-clients with the CACHED base\n  return {\n    raw: cachedBase,\n    conversations: createConversationsClient(cachedBase),\n    messages: createMessagesClient(cachedBase),\n    // ... all sub-clients\n    tags: createTagsClient(cachedBase),\n    inboxes: createInboxesClient(cachedBase),\n    teammates: createTeammatesClient(cachedBase),\n    drafts: createDraftsClient(cachedBase),\n    templates: createTemplatesClient(cachedBase),\n    contacts: createContactsClient(cachedBase),\n  }\n}\n```\n\n**Check if `createInstrumentedBaseClient` is exported from `@skillrecordings/core/front/instrumented-client`.** If not, you may need to export it, or find another interception point. The key constraint: sub-clients MUST use the cached base.\n\n### 4. Tests\n\nCreate `packages/cli/tests/unit/commands/front/cache.test.ts`:\n\n```typescript\ndescribe('FrontResponseCache', () => {\n  it('returns cached data on hit', ...)\n  it('returns undefined on miss', ...)\n  it('expires hot tier entries after TTL', ...)\n  it('does not expire static tier entries', ...)\n  it('expires warm tier entries after TTL', ...)\n  it('invalidates by URL pattern on mutation', ...)\n  it('invalidateTier clears only matching tier', ...)\n  it('clear removes all entries', ...)\n  it('stats returns correct counts per tier', ...)\n  it('classifyUrl maps /inboxes to static', ...)\n  it('classifyUrl maps /tags to warm', ...)\n  it('classifyUrl maps /conversations to hot', ...)\n  it('classifyUrl maps /inboxes/xxx/conversations to hot (not static)', ...)\n  it('disabled cache always returns undefined', ...)\n})\n\ndescribe('extractResourcePath', () => {\n  it('extracts /conversations/cnv_xxx from /conversations/cnv_xxx/tags', ...)\n  it('extracts /tags from /tags', ...)\n  it('handles full URLs', ...)\n})\n```\n\nCreate `packages/cli/tests/unit/commands/front/cached-client.test.ts`:\n```typescript\ndescribe('getFrontClient with cache', () => {\n  it('caches GET responses', ...)\n  it('returns cached response on second call', ...)\n  it('invalidates cache after POST', ...)\n  it('invalidates cache after PATCH', ...)\n  it('sub-clients use cached base (conversations.get hits cache)', ...)\n})\n```\n\n### 5. Wire bulk-archive.ts and pull-conversations.ts to use getFrontClient\n\nThese two files still import `createInstrumentedFrontClient` directly. Update them to import `getFrontClient` from `./client` so they benefit from caching.\n\n## Important\n- The cache is MODULE-LEVEL (singleton per process). For CLI: dies with process. For MCP: persists across tool calls. This is correct behavior.\n- `resetFrontCache()` must be exported for testing.\n- Do NOT cache error responses (4xx, 5xx). Only cache successful GET responses.\n- Pagination: cache each page URL separately. `/conversations?limit=50&page=2` is a different cache key from page 1.\n- The `classifyUrl` must handle `/inboxes/xxx/conversations` as HOT, not static. Only `/inboxes` (the list endpoint) is static.\n\n## Progress Notification\nOn completion, append to `packages/cli/PROGRESS.md`:\n```\n## Intelligent Front API Response Caching\n- Created FrontResponseCache with 3-tier TTL (static/warm/hot)\n- Static (∞): inbox list, teammates\n- Warm (5min): tags\n- Hot (30s): conversations, messages\n- Mutation invalidation: POST/PATCH/DELETE invalidate related cache entries\n- Cache wraps at base client level — all sub-clients (conversations, tags, etc.) get caching transparently\n- Module-level singleton: dies with CLI process, persists in MCP mode\n- Fixed bulk-archive.ts and pull-conversations.ts to use shared getFrontClient()\n- Added comprehensive tests for cache behavior, TTL, invalidation\n```",
      "priority": 1,
      "passes": true,
      "validationCommand": "cd packages/cli && bun run check-types && bun run test",
      "acceptanceCriteria": [
        "packages/cli/src/commands/front/cache.ts exists with FrontResponseCache class",
        "FrontResponseCache has 3 TTL tiers: static (Infinity), warm (5min), hot (30s)",
        "classifyUrl correctly maps URLs to tiers",
        "Mutation (POST/PATCH/DELETE) invalidates related cache entries",
        "Cache wraps at base client level so sub-clients get caching transparently",
        "getFrontClient() returns cached client by default",
        "resetFrontCache() exported for testing",
        "Error responses are NOT cached",
        "bulk-archive.ts and pull-conversations.ts updated to use getFrontClient from client.ts",
        "Unit tests for cache: TTL expiry, invalidation, tier classification, stats",
        "Integration test: sub-clients use cached base",
        "All existing tests pass"
      ]
    },
    {
      "id": "story-ml8n6vr5",
      "title": "Proactive rate limiter with token bucket for Front API (100 req/min shared budget)",
      "description": "## Problem\nFront API has a SHARED rate limit of 100 requests per minute across ALL users of the API key (all team members, webhooks, CLI, support agent — everything). The current instrumented client only handles 429s reactively (retry with backoff). By the time you get a 429, you've already burned requests and delayed the entire pipeline.\n\nWe need proactive throttling that:\n1. Spreads requests evenly across the minute (600ms minimum gap at max throughput)\n2. Doesn't blast 50 requests in 2 seconds then wait 58 seconds\n3. Respects the shared budget — assume other consumers exist\n4. Works WITH the cache layer (cached responses don't consume rate limit tokens)\n\n## Architecture: Token Bucket Rate Limiter\n\n### 1. Create `packages/cli/src/commands/front/rate-limiter.ts`\n\nImplement a token bucket rate limiter:\n\n```typescript\nexport interface RateLimiterConfig {\n  /** Max requests per window. Default: 80 (leave 20% headroom for webhooks/other users) */\n  maxRequests: number\n  /** Window size in ms. Default: 60_000 (1 minute) */\n  windowMs: number\n  /** Minimum gap between requests in ms. Default: 200 (smooths burst) */\n  minGapMs: number\n  /** Whether to queue and wait, or reject immediately. Default: 'queue' */\n  overflowStrategy: 'queue' | 'reject'\n  /** Max queue depth before rejecting. Default: 50 */\n  maxQueueDepth: number\n}\n\nexport const DEFAULT_RATE_LIMITER_CONFIG: RateLimiterConfig = {\n  maxRequests: 80,       // 80 of 100 — leave 20% headroom for other API consumers\n  windowMs: 60_000,\n  minGapMs: 200,         // Max ~5 req/sec even in bursts\n  overflowStrategy: 'queue',\n  maxQueueDepth: 50,\n}\n```\n\n**Token bucket implementation:**\n\n```typescript\nexport class FrontRateLimiter {\n  private timestamps: number[] = []  // Ring buffer of request timestamps\n  private lastRequestMs = 0\n  private queue: Array<{ resolve: () => void; reject: (err: Error) => void }> = []\n  private draining = false\n  private config: RateLimiterConfig\n\n  constructor(config: Partial<RateLimiterConfig> = {}) {\n    this.config = { ...DEFAULT_RATE_LIMITER_CONFIG, ...config }\n  }\n\n  /** Call before making a request. Resolves when it's safe to proceed. */\n  async acquire(): Promise<void> {\n    // Prune timestamps outside the window\n    const now = Date.now()\n    const windowStart = now - this.config.windowMs\n    this.timestamps = this.timestamps.filter(ts => ts > windowStart)\n\n    // Check if we have budget\n    if (this.timestamps.length < this.config.maxRequests) {\n      // Enforce minimum gap between requests\n      const timeSinceLast = now - this.lastRequestMs\n      if (timeSinceLast < this.config.minGapMs) {\n        await this.sleep(this.config.minGapMs - timeSinceLast)\n      }\n      this.timestamps.push(Date.now())\n      this.lastRequestMs = Date.now()\n      return\n    }\n\n    // Over budget — queue or reject\n    if (this.config.overflowStrategy === 'reject') {\n      throw new Error(`Rate limit exceeded: ${this.config.maxRequests} requests per ${this.config.windowMs}ms`)\n    }\n\n    if (this.queue.length >= this.config.maxQueueDepth) {\n      throw new Error(`Rate limiter queue full (${this.config.maxQueueDepth} pending)`)\n    }\n\n    // Queue the request — wait until a slot opens\n    return new Promise<void>((resolve, reject) => {\n      this.queue.push({ resolve, reject })\n      this.startDraining()\n    })\n  }\n\n  /** Record that a request was served from cache (no API call made) */\n  recordCacheHit(): void {\n    // No-op for rate limiting — cache hits don't consume API budget\n  }\n\n  /** Record a 429 response — adjust our window estimate */\n  record429(retryAfterMs?: number): void {\n    // We got rate limited despite our tracking — another consumer used budget\n    // Reduce our effective limit temporarily\n    if (retryAfterMs) {\n      // Pause all requests for the retry-after period\n      // The queue drainer will respect this\n      this.lastRequestMs = Date.now() + retryAfterMs\n    }\n  }\n\n  /** Get current utilization stats */\n  stats(): {\n    requestsInWindow: number\n    maxRequests: number\n    utilizationPct: number\n    queueDepth: number\n    estimatedWaitMs: number\n  } {\n    const now = Date.now()\n    const windowStart = now - this.config.windowMs\n    const inWindow = this.timestamps.filter(ts => ts > windowStart).length\n    const utilization = (inWindow / this.config.maxRequests) * 100\n\n    // Estimate wait: when will the oldest request in window expire?\n    let estimatedWaitMs = 0\n    if (inWindow >= this.config.maxRequests && this.timestamps.length > 0) {\n      const oldest = this.timestamps[0]!\n      estimatedWaitMs = Math.max(0, (oldest + this.config.windowMs) - now)\n    }\n\n    return {\n      requestsInWindow: inWindow,\n      maxRequests: this.config.maxRequests,\n      utilizationPct: Math.round(utilization),\n      queueDepth: this.queue.length,\n      estimatedWaitMs,\n    }\n  }\n\n  /** Reset limiter state (for testing) */\n  reset(): void {\n    this.timestamps = []\n    this.lastRequestMs = 0\n    for (const waiter of this.queue) {\n      waiter.reject(new Error('Rate limiter reset'))\n    }\n    this.queue = []\n    this.draining = false\n  }\n\n  private async startDraining(): Promise<void> {\n    if (this.draining) return\n    this.draining = true\n\n    while (this.queue.length > 0) {\n      const now = Date.now()\n      const windowStart = now - this.config.windowMs\n      this.timestamps = this.timestamps.filter(ts => ts > windowStart)\n\n      if (this.timestamps.length < this.config.maxRequests) {\n        // Enforce min gap\n        const timeSinceLast = now - this.lastRequestMs\n        if (timeSinceLast < this.config.minGapMs) {\n          await this.sleep(this.config.minGapMs - timeSinceLast)\n        }\n\n        const waiter = this.queue.shift()\n        if (waiter) {\n          this.timestamps.push(Date.now())\n          this.lastRequestMs = Date.now()\n          waiter.resolve()\n        }\n      } else {\n        // Wait until oldest timestamp expires from window\n        const oldest = this.timestamps[0]!\n        const waitMs = Math.max(100, (oldest + this.config.windowMs) - Date.now())\n        await this.sleep(waitMs)\n      }\n    }\n\n    this.draining = false\n  }\n\n  private sleep(ms: number): Promise<void> {\n    return new Promise(resolve => setTimeout(resolve, ms))\n  }\n}\n```\n\n### 2. Integrate into the cached client wrapper\n\nIn `packages/cli/src/commands/front/client.ts`, the cached client wrapper should:\n1. Check cache FIRST (no rate limit token consumed)\n2. If cache miss, `await rateLimiter.acquire()` BEFORE making the actual fetch\n3. On 429 response, call `rateLimiter.record429(retryAfterMs)`\n\nThe integration point is in the `cachedBase` wrapper from the caching story:\n\n```typescript\n// Module-level rate limiter — shared across all client instances\nlet sharedRateLimiter: FrontRateLimiter | null = null\n\nfunction getSharedRateLimiter(): FrontRateLimiter {\n  if (!sharedRateLimiter) {\n    sharedRateLimiter = new FrontRateLimiter()\n  }\n  return sharedRateLimiter\n}\n\nexport function resetFrontRateLimiter(): void {\n  sharedRateLimiter?.reset()\n  sharedRateLimiter = null\n}\n\n// In the cached client wrapper:\nconst cachedBase = {\n  get: async <T>(path: string, schema?: any): Promise<T> => {\n    const cached = cache.get<T>(path)\n    if (cached !== undefined) {\n      rateLimiter.recordCacheHit()\n      return cached\n    }\n    await rateLimiter.acquire()  // Wait for rate limit slot\n    const result = await inner.raw.get<T>(path, schema)\n    cache.set(path, result)\n    return result\n  },\n  post: async <T>(path: string, body: unknown, schema?: any): Promise<T> => {\n    await rateLimiter.acquire()\n    const result = await inner.raw.post<T>(path, body, schema)\n    cache.invalidate(extractResourcePath(path))\n    return result\n  },\n  // ... same for patch, put, delete\n}\n```\n\n### 3. Warn on high utilization\n\nWhen rate limiter utilization exceeds 80%, emit a warning via `ctx.output.warn()`. For MCP mode, include utilization stats in tool responses so agents can pace themselves.\n\n### 4. CLI flag for rate limit override\n\nAdd a `--rate-limit <n>` global option that overrides the default 80 req/min:\n```\nskill --rate-limit 50 front inbox \"Total TypeScript\"\n```\n\nThis is useful when you know other heavy consumers are active (e.g., the webhook pipeline is processing a batch).\n\n### 5. Tests\n\nCreate `packages/cli/tests/unit/commands/front/rate-limiter.test.ts`:\n\n```typescript\ndescribe('FrontRateLimiter', () => {\n  it('allows requests under budget', ...)\n  it('queues requests over budget', ...)\n  it('rejects when queue is full', ...)\n  it('enforces minimum gap between requests', ...)\n  it('drains queue as budget replenishes', ...)\n  it('record429 pauses requests for retry-after duration', ...)\n  it('stats returns correct utilization', ...)\n  it('reset clears all state and rejects queued', ...)\n  it('handles concurrent acquire calls', ...)\n  it('prunes old timestamps from window', ...)\n})\n```\n\nUse `vi.useFakeTimers()` for time-dependent tests. Test concurrent behavior with `Promise.all()`.\n\n### 6. Important edge cases\n- **Concurrent requests:** Multiple commands running simultaneously (e.g., MCP mode with parallel tool calls) must share the same limiter. The module-level singleton handles this.\n- **Queue ordering:** FIFO — first request to queue gets first slot. Don't starve long-running pagination.\n- **AbortSignal:** If a command is aborted (SIGINT), queued requests should be rejected. Check if the CommandContext signal is aborted in the acquire loop.\n- **Cache + rate limiter interaction:** Cache hits MUST NOT consume rate limit tokens. The check order is: cache → rate limiter → fetch.\n\n## Progress Notification\nOn completion, append to `packages/cli/PROGRESS.md`:\n```\n## Proactive Rate Limiter (100 req/min shared budget)\n- Token bucket with 80 req/min default (20% headroom for other consumers)\n- 200ms minimum gap between requests (smooths bursts to ~5 req/sec)\n- Queue-based overflow with configurable depth (50 default)\n- Integrates with cache: cache hits don't consume rate limit budget\n- 429 handling: record429() pauses all requests for Retry-After duration\n- Module-level singleton: shared across all client instances\n- Utilization stats for monitoring and agent awareness\n- --rate-limit CLI flag for manual override\n```",
      "priority": 2,
      "passes": false,
      "validationCommand": "cd packages/cli && bun run check-types && bun run test",
      "acceptanceCriteria": [
        "packages/cli/src/commands/front/rate-limiter.ts exists with FrontRateLimiter class",
        "Token bucket allows requests under budget without delay",
        "Requests over budget are queued and drained as budget replenishes",
        "Minimum 200ms gap between requests enforced",
        "Cache hits do NOT consume rate limit tokens",
        "record429() pauses requests for Retry-After duration",
        "Stats method returns utilization percentage and queue depth",
        "Reset method clears state and rejects queued waiters",
        "Rate limiter integrates with cached client wrapper (cache check before acquire)",
        "Module-level singleton shared across client instances",
        "resetFrontRateLimiter() exported for testing",
        "Unit tests with fake timers for all timing-dependent behavior",
        "All existing tests pass"
      ]
    }
  ],
  "metadata": {
    "createdAt": "2026-02-04T22:02:46.771Z",
    "lastIteration": "2026-02-04T23:22:38.006Z",
    "totalIterations": 6
  }
}